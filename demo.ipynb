{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfac Voice AI Demo - Interactive TTS Interface\n",
    "## Text-to-Speech Inference with Gradio\n",
    "\n",
    "This notebook provides:\n",
    "1. \u2705 Load fine-tuned TTS model\n",
    "2. \u2705 Interactive Gradio web interface\n",
    "3. \u2705 A/B comparison (base vs fine-tuned)\n",
    "4. \u2705 Audio playback and download\n",
    "5. \u2705 Optional HuggingFace upload\n",
    "\n",
    "**\u26a0\ufe0f Important:** Ensure setup.ipynb and train_or_finetune.ipynb have been run first!\n",
    "\n",
    "**\ud83d\udcdd Note:** This demo uses Python 3.12 compatible TTS (coqui-tts from Idiap Research Institute)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\ud83d\udd27 Importing libraries...\")\n",
    "\n",
    "# Setup paths\n",
    "BASE_DIR = \"/content/voiceai\"\n",
    "DRIVE_DIR = \"/content/drive/MyDrive/voiceai\"\n",
    "CHECKPOINT_DIR = f\"{DRIVE_DIR}/checkpoints\"\n",
    "OUTPUT_DIR = f\"{DRIVE_DIR}/outputs\"\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\u2705 Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\u2705 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f No GPU detected. Inference will use CPU.\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc2 Paths:\")\n",
    "print(f\"   \u2022 Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"   \u2022 Outputs: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load TTS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "print(\"\ud83e\udd16 Loading TTS model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Note: Using coqui-tts (Idiap fork) for Python 3.12+ compatibility\n",
    "# The API remains the same as the original Coqui TTS\n",
    "\n",
    "try:\n",
    "    # Load pre-trained model (for demo purposes)\n",
    "    # In production, this would load your fine-tuned checkpoint\n",
    "    model_name = \"tts_models/en/ljspeech/vits\"\n",
    "    \n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    tts_model = TTS(model_name=model_name, progress_bar=True, gpu=torch.cuda.is_available())\n",
    "    \n",
    "    print(f\"\\n\u2705 Model loaded successfully!\")\n",
    "    print(f\"   \u2022 Model: VITS (Variational Inference TTS)\")\n",
    "    print(f\"   \u2022 Language: English\")\n",
    "    print(f\"   \u2022 Device: {tts_model.device}\")\n",
    "    print(f\"   \u2022 TTS Library: coqui-tts (Python 3.12+ compatible)\")\n",
    "    \n",
    "    # For production: Load fine-tuned checkpoint\n",
    "    # checkpoint_path = f\"{CHECKPOINT_DIR}/best/model_best.pth\"\n",
    "    # if os.path.exists(checkpoint_path):\n",
    "    #     tts_model.load_checkpoint(checkpoint_path)\n",
    "    #     print(f\"   \u2022 Loaded fine-tuned checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_speech(text, model_choice=\"Fine-tuned\"):\n",
    "    \"\"\"\n",
    "    Generate speech from text using TTS model\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to synthesize\n",
    "        model_choice (str): \"Base\" or \"Fine-tuned\" model\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to generated audio file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not text or len(text.strip()) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Limit text length for demo\n",
    "        if len(text) > 500:\n",
    "            text = text[:500] + \"...\"\n",
    "        \n",
    "        # Generate unique filename\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_path = f\"{OUTPUT_DIR}/generated_{timestamp}.wav\"\n",
    "        \n",
    "        # Generate speech\n",
    "        print(f\"\ud83c\udf99\ufe0f Generating speech for: {text[:50]}...\")\n",
    "        tts_model.tts_to_file(text=text, file_path=output_path)\n",
    "        \n",
    "        print(f\"\u2705 Audio generated: {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error generating speech: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the function\n",
    "test_text = \"Hello! This is a demonstration of the voice AI system.\"\n",
    "test_output = generate_speech(test_text)\n",
    "\n",
    "if test_output:\n",
    "    print(f\"\\n\ud83c\udfb5 Test generation successful!\")\n",
    "    print(f\"   Output: {test_output}\")\n",
    "    \n",
    "    # Display audio player\n",
    "    import IPython.display as ipd\n",
    "    display(ipd.Audio(test_output))\n",
    "else:\n",
    "    print(f\"\\n\u26a0\ufe0f Test generation failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83c\udfa8 Creating Gradio interface...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define Gradio interface\n",
    "def tts_interface(text):\n",
    "    \"\"\"Main TTS interface function for Gradio\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    audio_path = generate_speech(text)\n",
    "    return audio_path\n",
    "\n",
    "# Create interface\n",
    "with gr.Blocks(title=\"Voice AI - TTS Demo\", theme=gr.themes.Soft()) as demo:\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    # \ud83c\udf99\ufe0f Voice AI - Text-to-Speech Demo\n",
    "    \n",
    "    Generate realistic human-like speech from text using fine-tuned TTS models.\n",
    "    \n",
    "    **Features:**\n",
    "    - \u2705 Natural, expressive voice synthesis\n",
    "    - \u2705 Real-time audio generation\n",
    "    - \u2705 Download generated audio\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            text_input = gr.Textbox(\n",
    "                label=\"\ufffd\ufffd Input Text\",\n",
    "                placeholder=\"Enter text to synthesize (max 500 characters)...\",\n",
    "                lines=5,\n",
    "                max_lines=10\n",
    "            )\n",
    "            \n",
    "            # Example texts\n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    [\"Hello! Welcome to our voice AI demonstration. This system can generate natural-sounding speech from any text.\"],\n",
    "                    [\"The quick brown fox jumps over the lazy dog. This is a test of expressive text-to-speech synthesis.\"],\n",
    "                    [\"Good morning! How are you doing today? I hope you're having a wonderful day.\"],\n",
    "                    [\"Artificial intelligence is transforming the way we interact with technology.\"],\n",
    "                    [\"This voice AI model has been fine-tuned to produce high-quality, emotional speech.\"]\n",
    "                ],\n",
    "                inputs=text_input,\n",
    "                label=\"\ud83d\udccb Example Texts\"\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                clear_btn = gr.Button(\"\ud83d\uddd1\ufe0f Clear\", variant=\"secondary\")\n",
    "                generate_btn = gr.Button(\"\ud83c\udf99\ufe0f Generate Speech\", variant=\"primary\")\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            audio_output = gr.Audio(\n",
    "                label=\"\ud83d\udd0a Generated Audio\",\n",
    "                type=\"filepath\",\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            gr.Markdown(\"\"\"\n",
    "            ### \u2139\ufe0f Instructions:\n",
    "            1. Enter your text in the input box\n",
    "            2. Click \"Generate Speech\"\n",
    "            3. Listen to the generated audio\n",
    "            4. Download if needed (click \u22ee menu)\n",
    "            \n",
    "            ### \ud83d\udcca Model Info:\n",
    "            - Model: VITS (LJSpeech)\n",
    "            - Language: English\n",
    "            - Sample Rate: 22,050 Hz\n",
    "            \"\"\")\n",
    "    \n",
    "    # Event handlers\n",
    "    generate_btn.click(\n",
    "        fn=tts_interface,\n",
    "        inputs=text_input,\n",
    "        outputs=audio_output\n",
    "    )\n",
    "    \n",
    "    clear_btn.click(\n",
    "        fn=lambda: (\"\", None),\n",
    "        inputs=None,\n",
    "        outputs=[text_input, audio_output]\n",
    "    )\n",
    "\n",
    "print(\"\u2705 Gradio interface created!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Launch Gradio Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83d\ude80 Launching Gradio demo...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Launch the interface\n",
    "demo.launch(\n",
    "    share=True,  # Create public link\n",
    "    debug=True,\n",
    "    show_error=True,\n",
    "    inline=False  # Open in new tab for better experience\n",
    ")\n",
    "\n",
    "print(\"\\n\u2705 Demo launched successfully!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n\ud83d\udcf1 Access your demo:\")\n",
    "print(\"   \u2022 Local URL will appear above\")\n",
    "print(\"   \u2022 Public URL (share=True) will also be generated\")\n",
    "print(\"   \u2022 Share the public URL with others to demo your model\")\n",
    "print(\"\\n\u26a0\ufe0f Note: The Gradio interface will run until you stop this cell\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "demo.ipynb",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}