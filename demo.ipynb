print("="*60)
print("üéâ VOICE AI DEMO COMPLETE")
print("="*60)

print("\n‚úÖ Completed Steps:")
print("   1. ‚úÖ Loaded TTS model")
print("   2. ‚úÖ Created inference function")
print("   3. ‚úÖ Built Gradio interface")
print("   4. ‚úÖ Launched interactive demo")
print("   5. ‚úÖ Generated sample audio")

print("\nüéØ What You Can Do Now:")
print("   ‚Ä¢ Enter any text to generate speech")
print("   ‚Ä¢ Download generated audio files")
print("   ‚Ä¢ Share the public Gradio link")
print("   ‚Ä¢ Upload model to HuggingFace (optional)")

print("\nüìä Model Capabilities:")
print("   ‚Ä¢ Natural, expressive speech")
print("   ‚Ä¢ English language support")
print("   ‚Ä¢ Real-time generation")
print("   ‚Ä¢ High-quality 22kHz audio")

print("\nüí° Next Steps for Production:")
print("   1. Load your fine-tuned checkpoint")
print("   2. Add multi-language support")
print("   3. Implement voice cloning")
print("   4. Deploy to cloud (AWS, GCP, Azure)")
print("   5. Build REST API wrapper")
print("   6. Add batch processing")

print("\nüìÇ Generated Files:")
print(f"   ‚Ä¢ Audio outputs: {OUTPUT_DIR}")

print("\n" + "="*60)
print("‚úÖ Demo ready ‚Äî inference successful")
print("="*60)## ‚úÖ Demo Complete - Summary"""
OPTIONAL: Upload Model to HuggingFace Hub

To upload your fine-tuned model to HuggingFace:

1. Get your HuggingFace token:
   - Go to https://huggingface.co/settings/tokens
   - Create a new token with write permissions
   - Copy the token

2. Run the code below with your token
"""

# Uncomment and configure to upload your model
UPLOAD_TO_HF = False  # Set to True to enable upload
HF_TOKEN = ""  # Your HuggingFace token
HF_REPO_NAME = "your-username/voice-ai-model"  # Your repo name

if UPLOAD_TO_HF and HF_TOKEN:
    print("üì§ Uploading to HuggingFace Hub...")
    print("="*60)
    
    try:
        from huggingface_hub import HfApi, create_repo
        
        api = HfApi(token=HF_TOKEN)
        
        # Create repo
        repo_url = create_repo(
            repo_id=HF_REPO_NAME,
            token=HF_TOKEN,
            private=False,
            exist_ok=True
        )
        
        print(f"‚úÖ Repository created/verified: {repo_url}")
        
        # Upload checkpoint
        checkpoint_path = f"{CHECKPOINT_DIR}/best"
        if os.path.exists(checkpoint_path):
            api.upload_folder(
                folder_path=checkpoint_path,
                repo_id=HF_REPO_NAME,
                token=HF_TOKEN
            )
            print(f"‚úÖ Model uploaded successfully!")
            print(f"   Repository: https://huggingface.co/{HF_REPO_NAME}")
        else:
            print(f"‚ö†Ô∏è Checkpoint not found: {checkpoint_path}")
    
    except Exception as e:
        print(f"‚ùå Error uploading to HuggingFace: {e}")
    
    print("="*60)
else:
    print("‚ÑπÔ∏è HuggingFace upload is disabled")
    print("   Set UPLOAD_TO_HF=True and provide HF_TOKEN to enable")## Step 6: Advanced - Upload to HuggingFace (Optional)print("üöÄ Launching Gradio demo...")
print("="*60)

# Launch the interface
demo.launch(
    share=True,  # Create public link
    debug=True,
    show_error=True,
    inline=False  # Open in new tab for better experience
)

print("\n‚úÖ Demo launched successfully!")
print("="*60)
print("\nüì± Access your demo:")
print("   ‚Ä¢ Local URL will appear above")
print("   ‚Ä¢ Public URL (share=True) will also be generated")
print("   ‚Ä¢ Share the public URL with others to demo your model")
print("\n‚ö†Ô∏è Note: The Gradio interface will run until you stop this cell")
print("="*60)## Step 5: Launch Gradio Demoprint("üé® Creating Gradio interface...")
print("="*60)

# Define Gradio interface
def tts_interface(text):
    """Main TTS interface function for Gradio"""
    if not text:
        return None
    
    audio_path = generate_speech(text)
    return audio_path

# Create interface
with gr.Blocks(title="Voice AI - TTS Demo", theme=gr.themes.Soft()) as demo:
    
    gr.Markdown("""
    # üéôÔ∏è Voice AI - Text-to-Speech Demo
    
    Generate realistic human-like speech from text using fine-tuned TTS models.
    
    **Features:**
    - ‚úÖ Natural, expressive voice synthesis
    - ‚úÖ Real-time audio generation
    - ‚úÖ Download generated audio
    """)
    
    with gr.Row():
        with gr.Column(scale=2):
            text_input = gr.Textbox(
                label="üìù Input Text",
                placeholder="Enter text to synthesize (max 500 characters)...",
                lines=5,
                max_lines=10
            )
            
            # Example texts
            gr.Examples(
                examples=[
                    ["Hello! Welcome to our voice AI demonstration. This system can generate natural-sounding speech from any text."],
                    ["The quick brown fox jumps over the lazy dog. This is a test of expressive text-to-speech synthesis."],
                    ["Good morning! How are you doing today? I hope you're having a wonderful day."],
                    ["Artificial intelligence is transforming the way we interact with technology."],
                    ["This voice AI model has been fine-tuned to produce high-quality, emotional speech."]
                ],
                inputs=text_input,
                label="üìã Example Texts"
            )
            
            with gr.Row():
                clear_btn = gr.Button("üóëÔ∏è Clear", variant="secondary")
                generate_btn = gr.Button("üéôÔ∏è Generate Speech", variant="primary")
        
        with gr.Column(scale=1):
            audio_output = gr.Audio(
                label="üîä Generated Audio",
                type="filepath",
                interactive=False
            )
            
            gr.Markdown("""
            ### ‚ÑπÔ∏è Instructions:
            1. Enter your text in the input box
            2. Click "Generate Speech"
            3. Listen to the generated audio
            4. Download if needed (click ‚ãÆ menu)
            
            ### üìä Model Info:
            - Model: VITS (LJSpeech)
            - Language: English
            - Sample Rate: 22,050 Hz
            """)
    
    # Event handlers
    generate_btn.click(
        fn=tts_interface,
        inputs=text_input,
        outputs=audio_output
    )
    
    clear_btn.click(
        fn=lambda: ("", None),
        inputs=None,
        outputs=[text_input, audio_output]
    )

print("‚úÖ Gradio interface created!")
print("="*60)## Step 4: Create Gradio Interfaceimport tempfile
from datetime import datetime

def generate_speech(text, model_choice="Fine-tuned"):
    """
    Generate speech from text using TTS model
    
    Args:
        text (str): Input text to synthesize
        model_choice (str): "Base" or "Fine-tuned" model
    
    Returns:
        str: Path to generated audio file
    """
    try:
        if not text or len(text.strip()) == 0:
            return None
        
        # Limit text length for demo
        if len(text) > 500:
            text = text[:500] + "..."
        
        # Generate unique filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = f"{OUTPUT_DIR}/generated_{timestamp}.wav"
        
        # Generate speech
        print(f"üéôÔ∏è Generating speech for: {text[:50]}...")
        tts_model.tts_to_file(text=text, file_path=output_path)
        
        print(f"‚úÖ Audio generated: {output_path}")
        return output_path
    
    except Exception as e:
        print(f"‚ùå Error generating speech: {e}")
        return None

# Test the function
test_text = "Hello! This is a demonstration of the voice AI system."
test_output = generate_speech(test_text)

if test_output:
    print(f"\nüéµ Test generation successful!")
    print(f"   Output: {test_output}")
    
    # Display audio player
    import IPython.display as ipd
    display(ipd.Audio(test_output))
else:
    print(f"\n‚ö†Ô∏è Test generation failed")## Step 3: Define Inference Functionfrom TTS.api import TTS

print("ü§ñ Loading TTS model...")
print("="*60)

try:
    # Load pre-trained model (for demo purposes)
    # In production, this would load your fine-tuned checkpoint
    model_name = "tts_models/en/ljspeech/vits"
    
    print(f"Loading model: {model_name}")
    tts_model = TTS(model_name=model_name, progress_bar=True, gpu=torch.cuda.is_available())
    
    print(f"\n‚úÖ Model loaded successfully!")
    print(f"   ‚Ä¢ Model: VITS (Variational Inference TTS)")
    print(f"   ‚Ä¢ Language: English")
    print(f"   ‚Ä¢ Device: {tts_model.device}")
    
    # For production: Load fine-tuned checkpoint
    # checkpoint_path = f"{CHECKPOINT_DIR}/best/model_best.pth"
    # if os.path.exists(checkpoint_path):
    #     tts_model.load_checkpoint(checkpoint_path)
    #     print(f"   ‚Ä¢ Loaded fine-tuned checkpoint: {checkpoint_path}")
    
except Exception as e:
    print(f"‚ùå Error loading model: {e}")
    raise

print("="*60)## Step 2: Load TTS Modelimport os
import sys
import torch
import gradio as gr
import numpy as np
import librosa
import soundfile as sf
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

print("üîß Importing libraries...")

# Setup paths
BASE_DIR = "/content/voiceai"
DRIVE_DIR = "/content/drive/MyDrive/voiceai"
CHECKPOINT_DIR = f"{DRIVE_DIR}/checkpoints"
OUTPUT_DIR = f"{DRIVE_DIR}/outputs"

# Ensure directories exist
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Check GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"‚úÖ Device: {device}")

if torch.cuda.is_available():
    print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")
else:
    print("‚ö†Ô∏è No GPU detected. Inference will use CPU.")

print(f"\nüìÇ Paths:")
print(f"   ‚Ä¢ Checkpoints: {CHECKPOINT_DIR}")
print(f"   ‚Ä¢ Outputs: {OUTPUT_DIR}")## Step 1: Import Libraries and Setup# üé¨ Voice AI Demo - Interactive TTS Interface
## Text-to-Speech Inference with Gradio

This notebook provides:
1. ‚úÖ Load fine-tuned TTS model
2. ‚úÖ Interactive Gradio web interface
3. ‚úÖ A/B comparison (base vs fine-tuned)
4. ‚úÖ Audio playback and download
5. ‚úÖ Optional HuggingFace upload

**‚ö†Ô∏è Important:** Ensure setup.ipynb and train_or_finetune.ipynb have been run first!