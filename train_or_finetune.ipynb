{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udf93 Voice AI Training System - Training & Fine-tuning\n",
    "## Dataset Preparation, Preprocessing, and Model Training\n",
    "\n",
    "This notebook will:\n",
    "1. \u2705 Download and prepare LJSpeech dataset\n",
    "2. \u2705 Preprocess audio (resample, normalize, trim)\n",
    "3. \u2705 Split data into train/validation sets\n",
    "4. \u2705 Select optimal model based on GPU memory\n",
    "5. \u2705 Train/fine-tune TTS model with progress tracking\n",
    "6. \u2705 Validate and save checkpoints to Google Drive\n",
    "\n",
    "**\u26a0\ufe0f Important:** Ensure setup.ipynb has been run first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "BASE_DIR = \"/content/voiceai\"\n",
    "DRIVE_DIR = \"/content/drive/MyDrive/voiceai\"\n",
    "DATASET_DIR = f\"{BASE_DIR}/dataset\"\n",
    "PROCESSED_DIR = f\"{BASE_DIR}/processed\"\n",
    "CHECKPOINT_DIR = f\"{DRIVE_DIR}/checkpoints\"\n",
    "OUTPUT_DIR = f\"{DRIVE_DIR}/outputs\"\n",
    "LOG_DIR = f\"{DRIVE_DIR}/logs\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [BASE_DIR, DATASET_DIR, PROCESSED_DIR, CHECKPOINT_DIR, OUTPUT_DIR, LOG_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\ud83d\udd27 Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"\ud83d\udd27 GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    print(f\"\ud83d\udd27 GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f No GPU detected! Training will be very slow.\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc2 Paths configured:\")\n",
    "print(f\"  \u2022 Dataset: {DATASET_DIR}\")\n",
    "print(f\"  \u2022 Processed: {PROCESSED_DIR}\")\n",
    "print(f\"  \u2022 Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"  \u2022 Outputs: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download LJSpeech Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "# LJSpeech download URL\n",
    "LJSPEECH_URL = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
    "LJSPEECH_PATH = f\"{DATASET_DIR}/LJSpeech-1.1\"\n",
    "\n",
    "print(\"\ud83d\udce5 Downloading LJSpeech dataset...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check if already downloaded\n",
    "if os.path.exists(LJSPEECH_PATH) and os.path.exists(f\"{LJSPEECH_PATH}/metadata.csv\"):\n",
    "    print(\"\u2705 LJSpeech dataset already exists!\")\n",
    "    print(f\"   Path: {LJSPEECH_PATH}\")\n",
    "else:\n",
    "    try:\n",
    "        # Download dataset\n",
    "        tar_path = f\"{DATASET_DIR}/LJSpeech-1.1.tar.bz2\"\n",
    "        \n",
    "        if not os.path.exists(tar_path):\n",
    "            print(\"\u23f3 Downloading... This may take 5-10 minutes (2.6 GB)\")\n",
    "            \n",
    "            def download_progress(block_num, block_size, total_size):\n",
    "                downloaded = block_num * block_size\n",
    "                percent = min(downloaded * 100 / total_size, 100)\n",
    "                sys.stdout.write(f'\\r  Progress: {percent:.1f}% ({downloaded/(1024**3):.2f} GB / {total_size/(1024**3):.2f} GB)')\n",
    "                sys.stdout.flush()\n",
    "            \n",
    "            urllib.request.urlretrieve(LJSPEECH_URL, tar_path, download_progress)\n",
    "            print(\"\\n\u2705 Download complete!\")\n",
    "        \n",
    "        # Extract dataset\n",
    "        print(\"\ud83d\udce6 Extracting dataset...\")\n",
    "        with tarfile.open(tar_path, 'r:bz2') as tar:\n",
    "            tar.extractall(path=DATASET_DIR)\n",
    "        \n",
    "        print(\"\u2705 Extraction complete!\")\n",
    "        \n",
    "        # Remove tar file to save space\n",
    "        if os.path.exists(tar_path):\n",
    "            os.remove(tar_path)\n",
    "            print(\"\u2705 Cleaned up temporary files\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error downloading dataset: {e}\")\n",
    "        print(\"You can manually download from: https://keithito.com/LJ-Speech-Dataset/\")\n",
    "        raise\n",
    "\n",
    "# Verify dataset\n",
    "metadata_path = f\"{LJSPEECH_PATH}/metadata.csv\"\n",
    "wavs_path = f\"{LJSPEECH_PATH}/wavs\"\n",
    "\n",
    "if os.path.exists(metadata_path) and os.path.exists(wavs_path):\n",
    "    num_wavs = len(list(Path(wavs_path).glob(\"*.wav\")))\n",
    "    print(f\"\\n\u2705 Dataset verified!\")\n",
    "    print(f\"   \u2022 Metadata: {metadata_path}\")\n",
    "    print(f\"   \u2022 Audio files: {num_wavs} wav files\")\n",
    "    print(f\"   \u2022 Total size: ~2.6 GB\")\n",
    "else:\n",
    "    print(\"\u274c Dataset verification failed!\")\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\ud83d\udcca Loading dataset metadata...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load metadata\n",
    "metadata_path = f\"{LJSPEECH_PATH}/metadata.csv\"\n",
    "df = pd.read_csv(metadata_path, sep='|', header=None, names=['filename', 'transcript', 'normalized_transcript'])\n",
    "\n",
    "print(f\"\u2705 Loaded {len(df)} samples\")\n",
    "print(f\"\\n\ufffd\ufffd Dataset Statistics:\")\n",
    "print(f\"   \u2022 Total samples: {len(df)}\")\n",
    "print(f\"   \u2022 Columns: {list(df.columns)}\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\n\ud83d\udcdd Sample transcripts:\")\n",
    "print(df[['filename', 'transcript']].head())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\n\ud83d\udd0d Data Quality:\")\n",
    "print(f\"   \u2022 Missing transcripts: {df['transcript'].isna().sum()}\")\n",
    "print(f\"   \u2022 Missing filenames: {df['filename'].isna().sum()}\")\n",
    "\n",
    "# Calculate transcript lengths\n",
    "df['transcript_length'] = df['transcript'].str.len()\n",
    "print(f\"\\n\ud83d\udccf Transcript Length Statistics:\")\n",
    "print(f\"   \u2022 Mean: {df['transcript_length'].mean():.1f} characters\")\n",
    "print(f\"   \u2022 Min: {df['transcript_length'].min()} characters\")\n",
    "print(f\"   \u2022 Max: {df['transcript_length'].max()} characters\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_or_finetune.ipynb",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}